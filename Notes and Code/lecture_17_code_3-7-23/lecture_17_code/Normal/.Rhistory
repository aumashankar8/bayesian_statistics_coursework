b1=r*sy/sx
b0=ybar-b1*xbar
c(b0,b1)
x.pred=50
y.pred=b0+b1*x.pred
y.pred
R.sq=r^2
R.sq
r
n=8
r=.688
df.r=n-2
SE.r=sqrt((1-r^2)/df.r)
t=r/SE.r
alpha=.05
t.crit=qt(1-alpha/2,df.r)
p.val=2*(1-pt(abs(t),df.r))
c(t,t.crit,p.val)
l=r-t.crit*SE.r
u=r+t.crit*SE.r
c(l,u)  # 9
n=16
r=-0.402
df.r=n-2
SE.r=sqrt((1-r^2)/df.r)
t=r/SE.r
alpha=.05
t.crit=qt(1-alpha/2,df.r)
p.val=2*(1-pt(abs(t),df.r))
c(t,t.crit,p.val)
n=32
r=-0.402
df.r=n-2
SE.r=sqrt((1-r^2)/df.r)
t=r/SE.r
alpha=.05
t.crit=qt(1-alpha/2,df.r)
p.val=2*(1-pt(abs(t),df.r))
c(t,t.crit,p.val)
r
l=r-t.crit*SE.r
u=r+t.crit*SE.r
c(l,u)  # 95
y=c(105,150,159,159,192,210,240,210,270)  # Calories
x=c(3.5,5.1,5.2,5.3,6.2,7.0,8.0,8.0,10.0) # ABV
plot(x,y)
n=length(y)
ybar=mean(y)
xbar=mean(x)
sy=sd(y)
sx=sd(x)
r=cor(y,x)
b1=r*sy/sx
b0=ybar-b1*xbar
c(b0,b1)
x.pred=9
y.pred=b0+b1*x.pred
y.pred
abline(b0,b1)
n=11
r=0.626
SEr=sqrt((1-r)/(n-2))
t=r/SEr
alpha=0.05
t.crit=qt(1-alpha/2,n-2)
t
n=11
r=0.626
df.r=n-2
SEr=sqrt((1-r)/df.r)
t=r/SEr
alpha=0.05
t.crit=qt(1-alpha/2,df.r)
p.val=2*(1-pt(t,df.r))
c(t,t.crit,p.val)
SEr
n=11
r=0.626
df.r=n-2
SEr=sqrt((1-r^2)/df.r)
t=r/SEr
alpha=0.05
t.crit=qt(1-alpha/2,df.r)
p.val=2*(1-pt(t,df.r))
c(t,t.crit,p.val)
SE.b1=4.848
b1=11.677
l=b1-t.crit*SE.b1
u=b1+t.crit*SE.b1
c(l,u)
n=18
b0=0.182
b1=0.029
SE.b1=.005
t=b1/SEb
n=18
b0=0.182
b1=0.029
SE.b1=.005
t=b1/SE.b1
alpha=0.05
t.crit=qt(1-alpha/2,df.r)
p.val=2*(1-pt(t,df.r))
c(t,t.crit,p.val)
c(t,t.crit,p.val)
n=18
df.r=n-2
b0=0.182
b1=0.029
SE.b1=.005
t=b1/SE.b1
alpha=0.05
t.crit=qt(1-alpha/2,df.r)
p.val=2*(1-pt(t,df.r))
c(t,t.crit,p.val)
y=c(105,150,159,159,192,210,240,210,270)  # Calories
x=c(3.5,5.1,5.2,5.3,6.2,7.0,8.0,8.0,10.0) # ABV
plot(x,y)
n=length(y)
ybar=mean(y)
xbar=mean(x)
sy=sd(y)
sx=sd(x)
r=cor(y,x)
b1=r*sy/sx
b0=ybar-b1*xbar
c(b0,b1)
x.pred=9
y.pred=b0+b1*x.pred
y.pred
R.sq=r^2
R.sq
y.hat=b0+b1*x
e=y-y.hat
SSE=sum(e^2)  # also called SSresid b/c it's estimate of SSE
SST=(n-1)*sy^2
SSR=SST-SSE  # SS regression!
SSR/SST
MSE=SSE/(n-2)
SE.b1=sqrt(MSE/sum((x-mean(x))^2)))
SE.b1=sqrt(MSE/sum((x-mean(x))^2))
SE.b1
n=9
n=length(y)
n
MSE=SSE/(n-2)
SE.b1=sqrt(MSE/sum((x-mean(x))^2))
t=b1/SE.b1
alpha=.05
t.crit=qt(1-alpha/2,n-2)
p.val=2*(1-pt(t,n-2))
c(t,t.crit,p.value)
c(t,t.crit,p.val)
n
y=c(105,150,159,159,192,210,240,210,270)  # Calories
x=c(3.5,5.1,5.2,5.3,6.2,7.0,8.0,8.0,10.0) # ABV
plot(x,y)
n=length(y)
ybar=mean(y)
n
xbar=mean(x)
sy=sd(y)
sx=sd(x)
r=cor(y,x)
b1=r*sy/sx
b0=ybar-b1*xbar
c(b0,b1)
x.pred=9
y.pred=b0+b1*x.pred
y.pred
R.sq=r^2
R.sq
# check R.sq
y.hat=b0+b1*x
e=y-y.hat
SSE=sum(e^2)  # also called SSresid b/c it's estimate of SSE
SST=(n-1)*sy^2
SSR=SST-SSE  # SS regression!
SSR/SST
# Test for slope (b1)
MSE=SSE/(n-2)
SE.b1=sqrt(MSE/sum((x-mean(x))^2))
t=b1/SE.b1
alpha=.05
t.crit=qt(1-alpha/2,n-2)
p.val=2*(1-pt(t,n-2))
c(t,t.crit,p.val)
l=b1-t.crit*SE.b1
u=b1+t.crit*SE.b1
c(l,u)
4.3+.34*3.5+.55*5-.12*2
n=11
r=0.626
df.r=n-2
SEr=sqrt((1-r^2)/df.r)
t=r/SEr
alpha=0.05
t.crit=qt(1-alpha/2,df.r)
p.val=2*(1-pt(t,df.r))
c(t,t.crit,p.val)
n=18
df.r=n-2
b0=0.182
b1=0.029
SE.b1=.005
t=b1/SE.b1
alpha=0.05
t.crit=qt(1-alpha/2,df.r)
p.val=2*(1-pt(t,df.r))
c(t,t.crit,p.val)
9.76-2.9-.22*2+.18*3-.32*2
.32*2
.18*3
.22*2
9.76 – 2.9*(1) – 0.22*(2) + 0.18*(3) – 0.32*(1*2)
9.76 - 2.9*(1) - 0.22*(2) + 0.18*(3) - 0.32*(1*2)
9.76 - 2.9 - 0.44 + 0.54 - 0.64
q()
(855.2/2)/(503.8/17)
855.2/2
503.8/17
?t.test
n=20
y1=rnorm(n,0,1)
y2=rnorm(n,.1,1)
t.test(y1,y2,var.equal=TRUE)
x=rep(0,2*n)
x[1:n]=1
y=c(y1,y2)
summary(lm(y~x))
prelim_data <- read.csv("~/Desktop/prelim_data.csv")
View(prelim_data)
prelim_data <- read.csv("~/Desktop/prelim_data.csv")
elim <- prelim[prelim$diff_wbc > -3.7 & prelim$diff_wbc < 2.7, ]
elim2 <- elim[elim$basal_alt > -22 & elim$basal_alt < 122, ]
prelim <- read.csv("~/Desktop/prelim_data.csv")
elim <- prelim[prelim$diff_wbc > -3.7 & prelim$diff_wbc < 2.7, ]
elim2 <- elim[elim$basal_alt > -22 & elim$basal_alt < 122, ]
elim2$logalt <- log(elim2$basal_alt)
elim2$logalt_c <- elim2$logalt - mean(elim2$logalt)
mymodel1<-lm(diff_wbc~logalt_c*treatment, data=elim2)
summary(mymodel1)
library(ggplot2)
ggplot(elim2,aes(x=logalt,y=diff_wbc,color=treatment)) + geom_smooth(method='lm') + geom_point() + xlab('log of Initial ALT Concentration (U/L)') + ylab('Difference in WBC Count (WBC/microL)') + labs(col='Treatment') + ggtitle('Change in WBC Count by log Initial ALT Concentration and Treatment') +  theme_classic()
plot(elim2$logalt, elim2$diff_wbc, xlab='log Initial ALT Concentration (U/L)', ylab= 'Change in WBC Count (WBC/microL)', main='Change in WBC Count by log Initial ALT Concentration', pch=20)
my_glm <- lm(diff_wbc ~ treatment + logalt, data=elim2)
hist(my_glm$residuals, main='Model Residuals', xlab='Residual', col='light grey', right=F)
plot(my_glm$fitted.values, my_glm$residuals, xlab= 'Fitted Values', ylab='Residuals', main='Residual Plot', pch=20)
abline(h=0, col='red')
#my_glm <- lm(diff_wbc ~ treatment + logalt, data=elim2)
my_glm <- lm(diff_wbc ~ treatment*logalt, data=elim2)
hist(my_glm$residuals, main='Model Residuals', xlab='Residual', col='light grey', right=F)
plot(my_glm$fitted.values, my_glm$residuals, xlab= 'Fitted Values', ylab='Residuals', main='Residual Plot', pch=20)
abline(h=0, col='red')
#my_glm <- lm(diff_wbc ~ treatment + logalt, data=elim2)
my_glm <- lm(diff_wbc ~ treatment*logalt_c, data=elim2)
hist(my_glm$residuals, main='Model Residuals', xlab='Residual', col='light grey', right=F)
plot(my_glm$fitted.values, my_glm$residuals, xlab= 'Fitted Values', ylab='Residuals', main='Residual Plot', pch=20)
abline(h=0, col='red')
elim2$treatment
summary(mymodel1)
library(ggplot2)
ggplot(elim2,aes(x=logalt,y=diff_wbc,color=treatment)) + geom_smooth(method='lm') + geom_point() + xlab('log of Initial ALT Concentration (U/L)') + ylab('Difference in WBC Count (WBC/microL)') + labs(col='Treatment') + ggtitle('Change in WBC Count by log Initial ALT Concentration and Treatment') +  theme_classic()
plot(elim2$logalt, elim2$diff_wbc, xlab='log Initial ALT Concentration (U/L)', ylab= 'Change in WBC Count (WBC/microL)', main='Change in WBC Count by log Initial ALT Concentration', pch=20)
ggplot(elim2,aes(x=logalt,y=diff_wbc,color=treatment)) + geom_smooth(method='lm') + geom_point() + xlab('log of Initial ALT Concentration (U/L)') + ylab('Difference in WBC Count (WBC/microL)') + labs(col='Treatment') + ggtitle('Change in WBC Count by log Initial ALT Concentration and Treatment') +  theme_classic()
log(.5)
theta=seq(0,1,,n.sim)
n.sim=1000
theta=seq(0,1,,n.sim)
kl=log(2(1-theta))
plot(theta,kl,type="l")
n.sim=1000
theta=seq(0,1,,n.sim)
kl=log(2(1-theta))
plot(theta,kl,type="l")
kl=log(2*(1-theta))
plot(theta,kl,type="l")
n.sim=1000
theta=seq(0,1,,n.sim)
kl=log(theta/.5)*theta+log((1-theta)/.5)*(1-theta)
plot(theta,kl,type="l")
Eq=theta
plot(theta,kl,type="l")
plot(theta,Eq-kl,type="l")
plot(theta,kl,type="l")
lines(theta,Eq-kl,col=2)
plot(theta,kl,type="l")
lines(theta,Eq+kl,col=2)
theta.opt=exp(-1)/(1+exp(-1))
plot(theta,kl,type="l")
lines(theta,Eq+kl,col=2)
abline(v=theta.opt,col=3)
plot(theta,kl,type="l")
lines(theta,Eq+kl,col=2)
lines(theta,Eq,col=4)
abline(v=theta.opt,col=3)
exp(-1)/(1+exp(-1))
theta=exp(-1)/(1+exp(-1))
n=100
y=rbinom(n,1,theta)
table(y)
theta=exp(-1)/(1+exp(-1))
n=100
y=rbinom(n,1,theta)
a=1
b=1
a.post=sum(y)+a
b.post=sum(1-y)+b
n.mc=10000
theta.samp=rbeta(n.mc,a.post,b.post)
q0.samp=(log(theta.samp/(1-theta.samp))+1)/2
layout(matrix(1:2,1,2))
hist(theta.samp,break=50)
theta=exp(-1)/(1+exp(-1))
n=100
y=rbinom(n,1,theta)
a=1
b=1
a.post=sum(y)+a
b.post=sum(1-y)+b
n.mc=10000
theta.samp=rbeta(n.mc,a.post,b.post)
q0.samp=(log(theta.samp/(1-theta.samp))+1)/2
layout(matrix(1:2,1,2))
hist(theta.samp,breaks=50)
hist(q0.samp,breaks=50)
theta=exp(-1)/(1+exp(-1))
q0=(log(theta/(1-theta))+1)/2
n=100
y=rbinom(n,1,theta)
a=1
b=1
a.post=sum(y)+a
b.post=sum(1-y)+b
n.mc=10000
theta.samp=rbeta(n.mc,a.post,b.post)
q0.samp=(log(theta.samp/(1-theta.samp))+1)/2
layout(matrix(1:2,1,2))
hist(theta.samp,breaks=50)
abline(v=theta,col=2)
hist(q0.samp,breaks=50)
abline(v=q0,col=2)
exp(-1)/(1+exp(-1))
exp(1)/(1+exp(1))
theta.l=exp(-1)/(1+exp(-1))
theta.u=exp(1)/(1+exp(1))
n.mcmc=100000
theta.save=rep(0,n.mcmc)
theta=.5
for(k in 1:n.mcmc){
theta.star=runif(1,theta.l,theta.u)
mh.1=sum(dbinom(y,1,theta.star,log=TRUE))
mh.2=sum(dbinom(y,1,theta,log=TRUE))
mh=exp(mh.1-mh.2){
theta.l=exp(-1)/(1+exp(-1))
theta.u=exp(1)/(1+exp(1))
n.mcmc=100000
theta.save=rep(0,n.mcmc)
theta=.5
for(k in 1:n.mcmc){
theta.star=runif(1,theta.l,theta.u)
mh.1=sum(dbinom(y,1,theta.star,log=TRUE))
mh.2=sum(dbinom(y,1,theta,log=TRUE))
mh=exp(mh.1-mh.2)
if(mh>runif(1)){
theta=theta.star
}
theta.save[k]=theta
}
q0.save=(log(theta.save/(1-theta.save))+1)/2
layout(matrix(1:2,1,2))
hist(theta.save,breaks=50)
abline(v=theta,col=2)
hist(q0.save,breaks=50)
abline(v=q0,col=2)
layout(matrix(1:2,1,2))
hist(theta.save,breaks=50,xlim=c(0,1))
abline(v=theta,col=2,lwd=2)
hist(q0.save,breaks=50,xlim=c(0,1))
abline(v=q0,col=2,lwd=2)
?det
a=2
b=c(1,3)
C=matrix(c(4,3,3,2),2,2)
solve(C)
mu.sig=0
s2.sig=1
log.sig=rnorm(10000,mu.sig,sqrt(s2.sig))
layout(matrix(1:2,1,2))
hist(log.sig)
hist(exp(log.sig)^2)
mu.sig=0
s2.sig=.1
log.sig=rnorm(10000,mu.sig,sqrt(s2.sig))
layout(matrix(1:2,1,2))
hist(log.sig)
hist(exp(log.sig)^2)
mu.sig=0
s2.sig=.2
log.sig=rnorm(10000,mu.sig,sqrt(s2.sig))
layout(matrix(1:2,1,2))
hist(log.sig)
hist(exp(log.sig)^2)
mu.sig=1
s2.sig=.1
log.sig=rnorm(10000,mu.sig,sqrt(s2.sig))
layout(matrix(1:2,1,2))
hist(log.sig)
hist(exp(log.sig)^2)
setwd("/Users/mh5379/Library/CloudStorage/Box-Box/teach/UT_Bayes_MS/2023/Code/lecture_17_code/lecture_17_code")
setwd("/Users/mh5379/Desktop/lecture_17_code")
setwd("~/Desktop/lecture_17_code/Bernoulli")
logit<-function(theta){log(theta)-log(1-theta)}
logit.inv<-function(x){exp(x)/(1+exp(x))}
ce.df=read.table("coexist.txt",header=TRUE)
head(ce.df)
n=dim(ce.df)[1]
y=ce.df$coexist
p=4
X=matrix(1,n,p)
X[,2]=scale(ce.df$elev)
X[,3]=scale(ce.df$maxdepth)
X[,4]=scale(ce.df$temp1)
pairs(cbind(y,X[,-1]))
summary(glm(y~0+X,family="binomial"))  # check MLE
library(rjags)
m.jags <-"
model{
for(i in 1:n){
y[i] ~ dbin(theta[i],N)
logit(theta[i]) <- b0+b1*X[i,2]+b2*X[i,3]+b3*X[i,4]
}
b0 ~ dnorm(mu,tau)
b1 ~ dnorm(mu,tau)
b2 ~ dnorm(mu,tau)
b3 ~ dnorm(mu,tau)
}
"
mod<-textConnection(m.jags)
mu=0
tau=1/2.25
m.out<-jags.model(mod,data=list('y'=y,'n'=n,'X'=X,'N'=1,'mu'=mu,'tau'=tau),n.chains=1,n.adapt=0) # build model and algorithm
n.mcmc=50000
n.burn=round(.2*n.mcmc)
update(m.out,n.burn) # perform burn-in
m.samples=jags.samples(m.out,c('b0','b1','b2','b3'),n.mcmc) # fit model post-burn-in
beta.post.mat=cbind(m.samples$b0[1,,1],m.samples$b1[1,,1],m.samples$b2[1,,1],m.samples$b3[1,,1])
matplot(beta.post.mat,type="l",lty=1,ylab=bquote(beta))
library(vioplot)
vioplot(data.frame(beta.post.mat),names=expression(beta[0],beta[1],beta[2],beta[3]))
abline(h=0,col=8)
apply(beta.post.mat,2,mean) # marginal posterior means for beta
apply(beta.post.mat,2,sd) # marginal posterior means for beta
apply(beta.post.mat,2,quantile,c(0.025,.975)) # marginal posterior 95% CI for beta
tmax.df=read.csv("laboratory_CTM.csv")
setwd("~/Desktop/lecture_17_code/Normal")
tmax.df=read.csv("laboratory_CTM.csv")
head(tmax.df)
n=dim(tmax.df)[1]
y=c(tmax.df$LRR_sustained)
p=5
X=matrix(1,n,p)
X[,1:4]=model.matrix(~0+tmax.df$species)
X[,5]=tmax.df$acclim_temp
pairs(cbind(y,X[,-1]))
summary(lm(y~0+X))  # check least squares fit
library(rjags)
m.jags <-"
model{
for(i in 1:n){
y[i] ~ dnorm(mu[i], tau)  # note: tau is precision=1/variance!
mu[i] = X[i,1:p]%*%beta
}
beta ~ dmnorm(mu.beta,Tau.beta)
tau <- pow(sig, -2)
sig ~ dunif(0,10)
}
"
mod<-textConnection(m.jags)
mu.beta=rep(0,p)
Sig.beta=10000*diag(p)
Tau.beta=solve(Sig.beta)
m.out<-jags.model(mod,data=list('y'=y,'n'=n,'X'=X,'p'=p,'mu.beta'=mu.beta,'Tau.beta'=Tau.beta),n.chains=1,n.adapt=0) # build model and algorithm
n.mcmc=50000
n.burn=round(.2*n.mcmc)
update(m.out,n.burn) # perform burn-in
m.samples=jags.samples(m.out,c('beta','sig'),n.mcmc) # fit model post-burn-in
layout(matrix(1:2,2,1))
matplot(t(m.samples$beta[,,1]),type="l",lty=1,ylab=bquote(beta))
plot(m.samples$sig[1,,1],type="l",lty=1,ylab=bquote(sigma))
library(vioplot)
layout(matrix(c(1,1,1,2),1,4))
vioplot(data.frame(t(m.samples$beta[1:4,,1])),names=expression(beta[1],beta[2],beta[3],beta[4]))
vioplot(data.frame(m.samples$beta[5,,1]),names=expression(beta[5]))
abline(h=0,col=8)
apply(m.samples$beta[,,1],1,mean) # marginal posterior means for beta
apply(m.samples$beta[,,1],1,sd) # marginal posterior means for beta
apply(m.samples$beta[,,1],1,quantile,c(0.025,.975)) # marginal posterior 95% CI for beta
mean(m.samples$beta[1,,1]>m.samples$beta[2,,1]) # Post prob: P(beta_1 > beta_2 | y) = 0.99
plot(m.samples$beta[1,,1],m.samples$beta[2,,1],col=rgb(0,0,0,.1),pch=16,cex=.5,asp=TRUE) # don't forget about joint inference!
abline(0,1,col=2)
n=30
p=3
X=matrix(1,n,p)
set.seed(101)
X[,2]=rnorm(n)
X[,3]=rnorm(n)
beta=c(.5,-1,2)
lambda=exp(X%*%beta)
y=rpois(n,lambda)  # simulate data
pairs(cbind(y,X[,-1]))
summary(glm(y~0+X,family=poisson(link="log")))  # check MLE
